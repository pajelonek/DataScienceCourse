{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Course\n",
    "### Classification \n",
    "#### Author: Pawel Jelonek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                name  \\\n0                           Planetwise Flannel Wipes   \n1                              Planetwise Wipe Pouch   \n2                Annas Dream Full Quilt with 2 Shams   \n3  Stop Pacifier Sucking without tears with Thumb...   \n4  Stop Pacifier Sucking without tears with Thumb...   \n\n                                              review  rating  \n0  These flannel wipes are OK, but in my opinion ...       3  \n1  it came early and was not disappointed. i love...       5  \n2  Very soft and comfortable and warmer than it l...       5  \n3  This is a product well worth the purchase.  I ...       5  \n4  All of my kids have cried non-stop when I trie...       5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>review</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Planetwise Flannel Wipes</td>\n      <td>These flannel wipes are OK, but in my opinion ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Planetwise Wipe Pouch</td>\n      <td>it came early and was not disappointed. i love...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Annas Dream Full Quilt with 2 Shams</td>\n      <td>Very soft and comfortable and warmer than it l...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n      <td>This is a product well worth the purchase.  I ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n      <td>All of my kids have cried non-stop when I trie...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "baby_df = pd.read_csv('amazon_baby.csv')\n",
    "baby_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 (data preparation)\n",
    "#### b) Replace all missing (nan) revies with empty \"\" string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "baby_df[\"review\"] = baby_df[\"review\"].fillna(\"\")\n",
    "#short test:\n",
    "baby_df[\"review\"][38] == \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### a) Remove punctuation from reviews using the given function.   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "#short test: \n",
    "baby_df[\"review\"] = baby_df[\"review\"].apply(lambda x: remove_punctuation(x))\n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### c) Drop all the entries with $rating = 3$, as they have neutral sentiment.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "baby_df = baby_df.drop(baby_df[baby_df.rating == 3].index)\n",
    "sum(baby_df[\"rating\"] == 3) == 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "def standardize_ratings(rating):\n",
    "    if rating >= 4: \n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "baby_df[\"rating\"] = baby_df[\"rating\"].map(lambda x: standardize_ratings(x))\n",
    "sum(baby_df[\"rating\"]**2 != 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "#### In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\"We like apples\",\n",
    "                   \"We hate oranges\",\n",
    "                   \"I adore bananas\",\n",
    "                   \"We like like apples and oranges\",\n",
    "                   \"They dislike bananas\"]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 \n",
    "#### a) Split dataset into training and test sets.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(baby_df['review'], baby_df['rating'], test_size = 0.2, random_state = 0)\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### b) Transform reviews into vectors using CountVectorizer. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "reviews_vectorized = vectorizer.fit_transform(xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 \n",
    "\n",
    "#### a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wall time: 7.6 s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(solver=\"lbfgs\",max_iter=10000).fit(reviews_vectorized,yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### b) Print 10 most positive and 10 most negative words."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Top 10 positive words\n",
      "('lifesaver', 2.213955598161604)\n",
      "('perfectly', 2.0679116719841493)\n",
      "('highly', 2.0231771059892654)\n",
      "('perfect', 1.9260397456299283)\n",
      "('plenty', 1.9070858570960028)\n",
      "('unlike', 1.8895098295785855)\n",
      "('glad', 1.8385306190195196)\n",
      "('love', 1.8124556174362176)\n",
      "('downside', 1.7841225417277407)\n",
      "('complaint', 1.751481701331609)\n",
      "\n",
      "Top 10 negative words\n",
      "('returning', -1.9486352651833716)\n",
      "('returned', -1.9983037445648912)\n",
      "('poorly', -2.0723897659000947)\n",
      "('worst', -2.077773012469216)\n",
      "('terrible', -2.10755677212824)\n",
      "('useless', -2.159703740524685)\n",
      "('disappointed', -2.1970904031803564)\n",
      "('waste', -2.3592952789588235)\n",
      "('disappointing', -2.4127341938902522)\n",
      "('poor', -2.6422263937989223)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Top 10 positive words\")\n",
    "words = list(zip(vectorizer.get_feature_names(),model.coef_.flatten()))\n",
    "words.sort(key=lambda w: w[1], reverse=True)\n",
    "\n",
    "dictionary = \"\"\n",
    "for x in words[:10]:\n",
    "    print(x)\n",
    "    dictionary +=str(x[0])+\" \"\n",
    "\n",
    "print(\"\\nTop 10 negative words\")\n",
    "for x in words[-10:]:\n",
    "    print(x)\n",
    "    dictionary +=str(x[0])+\" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 \n",
    "#### a) Predict the sentiment of test data reviews.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Skutecznosc predykcji wynosi: 98.38385655602531%\n",
      "Wall time: 51.9 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "predictions = model.predict(reviews_vectorized)\n",
    "suma0 = 0\n",
    "\n",
    "for i in range(0, len(yTest)):\n",
    "    if predictions[i] == yTest.values[i]:\n",
    "        suma0 = suma0 + 1\n",
    "\n",
    "print(\"Skutecznosc predykcji wynosi: \"+str((suma0/len(yTest))*100)+\"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### b) Predict the sentiment of test data reviews in terms of probability.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wall time: 15 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "predicted_sentiment = model.predict_proba(reviews_vectorized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### c) Find five most positive and most negative reviews.   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Top 10 reviews\n",
      "Review 1: This is a review of the 2012 Bumbleride Flite in R 1.0\n",
      "Review 2: We LOVE this seat As parents to 8 children ranging 1.0\n",
      "Review 3: Before my daughter was born in 2010 I bought the R 1.0\n",
      "Review 4: Were keeping this stroller After much research we  1.0\n",
      "Review 5: Warning long reviewShort versionProsfit wellwear w 1.0\n",
      "\n",
      "Top 10 worst reviews\n",
      "Review 1: This product should be in the hall of fame solely  1.1611051105337778e-16\n",
      "Review 2: Edited to Add 642010  Just wanted to add that Peg  6.676728298780986e-15\n",
      "Review 3: My husband and I are VERY disappointed and shocked 4.786323188982842e-14\n",
      "Review 4: Initially I thought these angled bottles make a lo 3.168521884487184e-13\n",
      "Review 5: THIS BASSINET IS OVERPRICED AND RIDICULOUS  If we  1.001302463424443e-12\n",
      "Wall time: 38.9 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "revs = list(zip(xTest, predicted_sentiment[:,1]))\n",
    "revs.sort(key = lambda x: x[1], reverse=True)\n",
    "print(\"Top 10 reviews\")\n",
    "for i, x in enumerate(revs[:5]):\n",
    "    print('Review {}:'.format(i+1), x[0][:50], x[1])\n",
    "print(\"\\nTop 10 worst reviews\")    \n",
    "for i, x in enumerate(reversed(revs[-5:])):\n",
    "    print('Review {}:'.format(i+1), x[0][:50], x[1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "#### In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "#### a) Redo exercises 2-5 using limited dictionary.   \n",
    "#### b) Check the impact of all the words from the dictionary.   \n",
    "#### c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest= train_test_split(baby_df['review'], baby_df['rating'], test_size = 0.2, random_state = 0)\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=dictionary.split())\n",
    "X_vectorized_to_our_dict = vectorizer.fit_transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wall time: 142 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "model_with_limited_dir = LogisticRegression(solver=\"lbfgs\",max_iter=10000).fit(X_vectorized_to_our_dict, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Skutecznosc predykcji wynosi: 87.13381907588978%\n",
      "Wall time: 55.9 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "predictions_with_limited_dir = model_with_limited_dir.predict(X_vectorized_to_our_dict)\n",
    "suma = 0\n",
    "\n",
    "for i in range(0, len(yTest)):\n",
    "    if predictions_with_limited_dir[i] == yTest.values[i]:\n",
    "        suma = suma + 1\n",
    "\n",
    "print(\"Skutecznosc predykcji wynosi: \"+str((suma/len(yTest))*100)+\"%\")\n",
    "predicted_sentiment = model_with_limited_dir.predict_proba(X_vectorized_to_our_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Top 10 reviews\n",
      "Review 1: I researched strollers for months and months befor 0.9999994053446656\n",
      "Review 2: We LOVE this seat As parents to 8 children ranging 0.9999991209510133\n",
      "Review 3: This diaper bag is PERFECT There are a lot of pock 0.9999960334017929\n",
      "Review 4: I bought this gym for our grandaughter  Her mother 0.9999906420766114\n",
      "Review 5: i love love love recaro and i love love love this  0.9999867999990523\n",
      "\n",
      "Top 10 worst reviews\n",
      "Review 1: I have five children We have owned several strolle 1.361683647842494e-05\n",
      "Review 2: I registered for this product and received it and  4.1426989855789376e-05\n",
      "Review 3: If we only knew when we registered how terrible th 0.00019288833706413138\n",
      "Review 4: Basically I just want to second Dressy Grad Studen 0.00024966938898068566\n",
      "Review 5: This was possibly the most disappointing electroni 0.00025022700525714173\n",
      "Wall time: 26.9 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "revs2 = list(zip(xTest, predicted_sentiment[:,1]))\n",
    "revs2.sort(key = lambda x: x[1], reverse=True)\n",
    "print(\"Top 10 reviews\")\n",
    "for i, x in enumerate(revs2[:5]):\n",
    "    print('Review {}:'.format(i+1), x[0][:50], x[1])\n",
    "print(\"\\nTop 10 worst reviews\")    \n",
    "for i, x in enumerate(reversed(revs2[-5:])):\n",
    "    print('Review {}:'.format(i+1), x[0][:50], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for limited dict\n",
      "1 = lifesaver = 1.9739819111588028\n",
      "2 = perfectly = 1.3599040828476456\n",
      "3 = highly = 1.7338576222649003\n",
      "4 = perfect = 1.339694409210868\n",
      "5 = plenty = 1.5045715293359114\n",
      "6 = unlike = 1.0689782392214933\n",
      "7 = glad = 1.175944820931581\n",
      "8 = love = 1.3790911093516982\n",
      "9 = downside = 1.9334764431053262\n",
      "10 = complaint = 1.2036867753882554\n",
      "11 = returning = -2.728921469081398\n",
      "12 = returned = -2.329746552102015\n",
      "13 = poorly = -2.647683464759656\n",
      "14 = worst = -2.351636691726289\n",
      "15 = terrible = -2.2474315296611747\n",
      "16 = useless = -2.006925464008881\n",
      "17 = disappointed = -2.437097349989623\n",
      "18 = waste = -2.5792479431372084\n",
      "19 = disappointing = -2.5642139743772567\n",
      "20 = poor = -2.2297623286054433\n",
      "\n",
      "Data for unlimited dict\n",
      "1 = lifesaver = 2.213955598161604\n",
      "2 = perfectly = 2.0679116719841493\n",
      "3 = highly = 2.0231771059892654\n",
      "4 = perfect = 1.9260397456299283\n",
      "5 = plenty = 1.9070858570960028\n",
      "6 = unlike = 1.8895098295785855\n",
      "7 = glad = 1.8385306190195196\n",
      "8 = love = 1.8124556174362176\n",
      "9 = downside = 1.7841225417277407\n",
      "10 = complaint = 1.751481701331609\n",
      "11 = returning = -1.9486352651833716\n",
      "12 = returned = -1.9983037445648912\n",
      "13 = poorly = -2.0723897659000947\n",
      "14 = worst = -2.077773012469216\n",
      "15 = terrible = -2.10755677212824\n",
      "16 = useless = -2.159703740524685\n",
      "17 = disappointed = -2.1970904031803564\n",
      "18 = waste = -2.3592952789588235\n",
      "19 = disappointing = -2.4127341938902522\n",
      "20 = poor = -2.6422263937989223\n"
     ]
    }
   ],
   "source": [
    "print(\"Data for limited dict\")\n",
    "len(model_with_limited_dir.coef_[0])\n",
    "len(vectorizer.get_feature_names())\n",
    "for i in range(0,len(vectorizer.get_feature_names())):\n",
    "    print(str(i+1)+\" = \"+str(vectorizer.get_feature_names()[i])+\" = \"+str(model_with_limited_dir.coef_[0][i]))\n",
    "print(\"\\nData for unlimited dict\")\n",
    "index = 1\n",
    "for x in words[:10]:\n",
    "    print(str(index)+\" = \"+x[0]+\" = \"+str(x[1]))\n",
    "    index = index+1\n",
    "\n",
    "for x in words[-10:]:\n",
    "    print(str(index)+\" = \"+x[0]+\" = \"+str(x[1]))\n",
    "    index = index +1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}